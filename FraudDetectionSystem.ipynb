{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 1: Load & Explore Data\n",
    "# -----------------------------------------\n",
    "data = pd.read_csv('/content/fraud_simulation_dataset.csv')\n",
    "\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(\"Missing values:\\n\", data.isnull().sum())\n",
    "print(\"isFraud distribution:\\n\", data['isFraud'].value_counts())\n",
    "\n",
    "# Simulate fraud if none exist (e.g., set 5% of transactions as fraud)\n",
    "if data['isFraud'].sum() == 0:\n",
    "    num_records = len(data)\n",
    "    num_fraud = max(1, int(0.05 * num_records))\n",
    "    fraud_indices = np.random.choice(data.index, num_fraud, replace=False)\n",
    "    data.loc[fraud_indices, 'isFraud'] = 1\n",
    "    print(f\"\\nSimulated {num_fraud} fraud transactions.\")\n",
    "    print(\"New isFraud distribution:\\n\", data['isFraud'].value_counts())\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 2: Data Cleaning\n",
    "# -----------------------------------------\n",
    "numeric_columns = data.select_dtypes(include=['number']).columns\n",
    "data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())\n",
    "\n",
    "# Drop irrelevant columns.\n",
    "data.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)\n",
    "\n",
    "# Remove outliers (extreme amounts beyond the 99th percentile).\n",
    "data = data[data['amount'] < data['amount'].quantile(0.99)]\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 3: Feature Engineering & Selection\n",
    "# -----------------------------------------\n",
    "data['balanceDiff'] = data['oldbalanceOrg'] - data['newbalanceOrig']\n",
    "\n",
    "# Encode categorical variable 'type'\n",
    "le = LabelEncoder()\n",
    "data['type'] = le.fit_transform(data['type'])\n",
    "\n",
    "# Separate target and predictors.\n",
    "y = data['isFraud']\n",
    "X = data.drop('isFraud', axis=1)\n",
    "\n",
    "# Drop highly correlated features.\n",
    "corr_matrix = X.corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.85)]\n",
    "print(\"\\nDropping columns due to high correlation:\", to_drop)\n",
    "X.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 4: Train-Test Split (Before SMOTE)\n",
    "# -----------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"\\nClass distribution in training set before SMOTE:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 5: Apply SMOTE on Training Data Only\n",
    "# -----------------------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "print(\"\\nClass distribution in training set after SMOTE:\")\n",
    "print(pd.Series(y_train_sm).value_counts())\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 6: Train XGBoost Model\n",
    "# -----------------------------------------\n",
    "scale_pos_weight = y_train_sm.value_counts()[0] / y_train_sm.value_counts()[1]\n",
    "xgb_clf = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42)\n",
    "xgb_clf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 7: Evaluate the Model\n",
    "# -----------------------------------------\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"\\nAUC-ROC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Feature Importance Plot\n",
    "xgb.plot_importance(xgb_clf)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------\n",
    "# Step 8: Hyperparameter Tuning (Optional)\n",
    "# -----------------------------------------\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'scale_pos_weight': [scale_pos_weight],\n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=xgb_clf,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='roc_auc',\n",
    "                                   cv=3,\n",
    "                                   verbose=0,\n",
    "                                   random_state=42)\n",
    "random_search.fit(X_train_sm, y_train_sm)\n",
    "#print(\"\\nBest Parameters from Hyperparameter Tuning:\")\n",
    "#print(random_search.best_params_)\n",
    "print(\"Best Score from Hyperparameter Tuning:\", random_search.best_score_)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Additional Section: Proactive Fraud Prevention & Monitoring Simulation\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def simulate_real_time_detection(model, transactions_df, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Simulates a real-time detection system. For each new transaction (row in transactions_df),\n",
    "    the model predicts the fraud probability. If the probability exceeds the threshold,\n",
    "    an alert is printed.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Real-Time Fraud Detection Simulation ---\")\n",
    "    for idx, transaction in transactions_df.iterrows():\n",
    "        # Reshape the transaction row to match model input dimensions.\n",
    "        trans_data = transaction.values.reshape(1, -1)\n",
    "        fraud_prob = model.predict_proba(trans_data)[0, 1]\n",
    "        if fraud_prob > threshold:\n",
    "            print(f\"Alert: Transaction {idx} flagged as potential fraud with probability {fraud_prob:.2f}\")\n",
    "        # In a real system, instead of sleeping, this function would process each incoming transaction continuously.\n",
    "        time.sleep(0.05)\n",
    "\n",
    "# Simulate real-time detection on a subset of the test set.\n",
    "simulate_sample = X_test.iloc[:20]  # only take 20 transactions as a sample\n",
    "simulate_real_time_detection(xgb_clf, simulate_sample, threshold=0.8)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Monitoring & Evaluation Dashboard (Conceptual)\n",
    "# ------------------------------------------------------------------------------\n",
    "# In a production system, you would deploy monitoring tools (e.g., Grafana dashboards)\n",
    "# to continuously track these key performance indicators:\n",
    "# - ROC-AUC and other classification metrics over time.\n",
    "# - Alert volume and the ratio of true alerts vs. false alarms.\n",
    "# - Time-to-detection for potential fraud events.\n",
    "#\n",
    "# For example, using a logging framework:\n",
    "#\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO, filename=\"fraud_detection.log\")\n",
    "# logging.info(\"New fraud alert generated at {timestamp}: Transaction {id} with probability {p}\".format(\n",
    "#     timestamp=time.strftime(\"%Y-%m-%d %H:%M:%S\"), id=transaction_id, p=fraud_prob))\n",
    "#\n",
    "# This log feeds into a dashboard where analysts can review model performance and adjust thresholds.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
